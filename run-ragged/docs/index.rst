.. RAG Demo documentation master file, created by
   sphinx-quickstart on Mon Jan 20 07:48:54 2025.

RAG API Service Documentation
=============================

## Overview

The RAG API Service is a robust backend application built with FastAPI that provides a Retrieval Augmented Generation (RAG) system for processing and querying PDF documents. It seamlessly integrates with various Google Cloud services, vector storage, and Large Language Model (LLM) capabilities to deliver intelligent document search and question-answering functionalities.

## Key Features

-   **PDF Document Storage:** Utilizes Google Cloud Storage (GCS) for storing PDF documents.
-   **Document Embeddings:** Employs Cloud SQL (PostgreSQL) with the pgvector extension to store document embeddings, enabling efficient similarity searches.
-   **LLM Integration:** Leverages Vertex AI for both generating embeddings and providing LLM capabilities for question answering. Supports models like `gemini-1.0-pro-001`.  Optional support for Grok LLM as well.
-   **Asynchronous Operations:** Leverages `asyncio` for non-blocking I/O operations, ensuring high performance and scalability.
-   **API Interface:** Provides a comprehensive API built with FastAPI for easy interaction with the RAG system.
-   **Metrics and Monitoring:** Includes Prometheus integration for collecting and exposing metrics related to performance and health.
-   **Resilience:** Implements a circuit breaker pattern for enhanced resilience against service outages.
-   **Configuration Management:** Utilizes environment variables for flexible and manageable configuration.
-   **Frontend:** Serves a React-based user interface for interacting with the API.
-   **Conversation Memory:** Utilizes conversation memory to maintain context over multiple turns of conversation.
-   **AI Collaboration:** Implements an AI collaboration manager to enable collaboration between different LLMs.

## Architecture

The application architecture consists of the following key components:

1.  **FastAPI Application:** Serves as the main API endpoint for handling incoming requests and routing them to the appropriate services.
2.  **Google Cloud Storage (GCS):** Stores the PDF documents that are processed by the system.  The bucket name is configured via the `PDF_BUCKET_NAME` environment variable.
3.  **Cloud SQL (PostgreSQL) with pgvector:** Stores document embeddings generated by Vertex AI.  The database connection is configured via `DB_INSTANCE_NAME`, `DB_USER`, `DB_PASS`, and `DB_NAME` environment variables.
4.  **Vertex AI:** Provides the `textembedding-gecko@003` model for generating document embeddings and the `gemini-1.0-pro-001` model for generating answers to user queries.
5.  **Indexer Service:** An external service (URL configured via `INDEXER_SERVICE_URL`) responsible for indexing PDF documents and creating embeddings. Communication is authenticated via a pre-shared key (`PRE_SHARED_KEY`).
6.  **Prometheus:** Collects metrics about the service's performance and health, which can be used for monitoring and alerting.
7.  **Circuit Breaker:** Protects the application from cascading failures by implementing circuit breakers for database, storage, and Vertex AI services.

## Setup and Installation

### Prerequisites

-   Google Cloud Account
-   Cloud SDK installed and configured
-   Docker and Docker Compose (optional, for local development)

### Environment Variables

The following environment variables are required for the application to run:

-   `DB_INSTANCE_NAME`: Cloud SQL instance connection name.
-   `DB_USER`: Database username.
-   `DB_PASS`: Database password.
-   `DB_NAME`: Database name.
-   `PDF_BUCKET_NAME`: GCS bucket for PDF storage.
-   `INDEXER_SERVICE_URL`: URL of the indexer service (e.g., `http://indexer:8080`).
-   `PRE_SHARED_KEY`: Pre-shared key for authenticating with the indexer service.

The following environment variables are optional:

-   `CIRCUIT_BREAKER_FAILURE_THRESHOLD`: Number of failures before circuit breaker trips (default: `3`).
-   `CIRCUIT_BREAKER_RECOVERY_TIMEOUT`: Time in seconds before circuit breaker recovers (default: `30`).
-   `LLM_MAX_OUTPUT_TOKENS`: Maximum number of tokens generated by the LLM (default: `2048`).
-   `LLM_MODEL_NAME`: Name of the LLM model to use (default: `"gemini-1.0-pro-001"`).
-   `LLM_TEMPERATURE`: Temperature setting for LLM generation (default: `0.2`).
-    `GROK_API_KEY`: API key for the Grok LLM service if you have one (optional when Grok is disabled)
-   `GROK_API_URL`: URL for the Grok LLM service (optional when Grok is disabled)
-   `INDEXER_HEALTH_CHECK_INTERVAL`: Interval in seconds between health checks for the indexer service (default: `60`).

## API Endpoints

-   `/`: Redirects to the UI.
-   `/api`: Displays the interactive API documentation (Swagger UI).
-   `/upload`: (POST) Uploads a PDF file for indexing. Requires authentication via `X-Pre-Shared-Key` header.
-   `/query`: (POST) Submits a query and retrieves an answer.
-   `/feedback`: (POST)  Submits user feedback on a previous answer.
-   `/health`: (GET) Performs a health check and returns the status of the service and its dependencies.
-   `/verify-vectorstore`: (GET) Verifies the connection to the vector store.
-   `/verify-indexer`: (GET) Verifies the connection to the indexer service.
-   `/debug/reset-conversation`: (POST) Resets the conversation memory. Requires authentication via `X-Pre-Shared-Key` header.
-   `/metrics`: (GET) Exposes Prometheus metrics.
-   `/docs`: Serves this documentation.

## Usage

### Uploading a PDF Document

To upload a PDF document, send a `POST` request to the `/upload` endpoint with the PDF file attached.  Include the `X-Pre-Shared-Key` header for indexer authentication.

.. toctree::
   :maxdepth: 3
   :caption: Contents:

   source/ai_collaboration
   source/conversation_memory
   source/indexer
   source/server